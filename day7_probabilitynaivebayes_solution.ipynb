{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Review of Probability Concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For and a review of probability concepts and a warm-up for today's main exercise, download and work through this notebook from a previous AI4ALL session: https://github.com/abisee/sailors2017/blob/master/lesson3_naivebayes_exercises.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes Spam Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create the spam classifier we learned about in today's lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Download and load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a spam classification dataset from here: https://www.kaggle.com/benvozza/spam-classification/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run the following code to read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spam.csv\", header=0, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell splits the dataset into a train and test set. We'll start with using 80% of the data for training and 20% for testing -- if you have time at the end of the session, you can come back and experiment with different train-test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples = data.shape[0]\n",
    "indices = np.random.permutation(num_examples)\n",
    "\n",
    "train_indices = indices[:int(num_examples * 4 / 5)]\n",
    "test_indices = indices[int(num_examples * 4 / 5):]\n",
    "\n",
    "train_data = data.iloc[train_indices]\n",
    "test_data = data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many train and test examples do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 5)\n",
      "(1115, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, the 'v1' column contains the labels and the 'v2' column contains the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_data['v1']\n",
    "train_inputs = train_data['v2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the possible labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Write functions to compute the probabilities we'll need for our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete these functions to calculate p(word|spam) and p(word|not spam) for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_train_indices = np.where(train_labels == 'spam')\n",
    "spam_inputs = train_inputs.iloc[spam_train_indices]\n",
    "\n",
    "ham_train_indices = np.where(train_labels == 'ham')\n",
    "ham_inputs = train_inputs.iloc[ham_train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_spam_words = np.concatenate([example.split(\" \") for example in spam_inputs.ravel()])\n",
    "all_ham_words = np.concatenate([example.split(\" \") for example in ham_inputs.ravel()])\n",
    "all_words = np.concatenate((all_spam_words, all_ham_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_p_word_given_spam(all_spam_words, word):\n",
    "    num_spam_words = len(all_spam_words)\n",
    "    num_word_occurrences = np.count_nonzero(all_spam_words == word)\n",
    "    return num_word_occurrences / num_spam_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_p_word_given_ham(all_ham_words, word):\n",
    "    num_ham_words = len(all_ham_words)\n",
    "    num_word_occurrences = np.count_nonzero(all_ham_words == word)\n",
    "    return num_word_occurrences / num_ham_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute p(spam), p(ham)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_spam = len(spam_inputs)\n",
    "num_ham = len(ham_inputs)\n",
    "num_total = num_spam + num_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_spam = num_spam / num_total\n",
    "p_ham = num_ham / num_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, complete the following function to compute p(word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_p_word(all_words, word):\n",
    "    num_word_occurrences = np.count_nonzero(all_words == word)\n",
    "    num_words = len(all_words)\n",
    "    return num_word_occurrences / num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate p(spam|word) and p(ham|word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_p_spam_given_word(all_spam_words, word, all_words, p_spam):\n",
    "    p_word_given_spam = compute_p_word_given_spam(all_spam_words, word)\n",
    "    p_word = compute_p_word(all_words, word)\n",
    "    p_spam_given_word = p_word_given_spam * p_spam / p_word\n",
    "    return p_spam_given_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_p_ham_given_word(all_ham_words, word, all_words, p_ham):\n",
    "    p_word_given_ham = compute_p_word_given_ham(all_ham_words, word)\n",
    "    p_word = compute_p_word(all_words, word)\n",
    "    p_ham_given_word = p_word_given_ham * p_ham / p_word\n",
    "    return p_ham_given_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following functions to compute p(email|spam), p(email|ham), and p(email)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_p_email_given_spam(all_spam_words, email):\n",
    "    p_email_given_spam = 1.0\n",
    "    for word in email:\n",
    "        p_word_given_spam = compute_p_word_given_spam(all_spam_words, word)\n",
    "        p_email_given_spam *= p_word_given_spam\n",
    "    return p_email_given_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_p_email_given_ham(all_ham_words, email):\n",
    "    p_email_given_ham = 1.0\n",
    "    for word in email:\n",
    "        p_word_given_ham = compute_p_word_given_ham(all_ham_words, word)\n",
    "        p_email_given_ham *= p_word_given_ham\n",
    "    return p_email_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_p_email(all_words, email):\n",
    "    p_email = 1.0\n",
    "    for word in email:\n",
    "        p_word = compute_p_word(all_words, word)\n",
    "        p_email *= p_word\n",
    "    return p_email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following classifier, which makes predictions by comparing p(spam|email) to p(not spam|email)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_email(email, all_spam_words, all_ham_words, all_words, p_spam, p_ham):\n",
    "    p_email_given_spam = compute_p_email_given_spam(all_spam_words, email)\n",
    "    p_email_given_ham = compute_p_email_given_ham(all_ham_words, email)\n",
    "    p_email = compute_p_email(all_words, email)\n",
    "    spam_probability = p_email_given_spam * p_spam\n",
    "    ham_probability = p_email_given_ham * p_ham\n",
    "    if spam_probability > ham_probability:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following function, which checks the test accuracy for our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier_accuracy(test_data, all_spam_words, all_ham_words, all_words, p_spam, p_ham):\n",
    "    num_test_examples = len(test_data)\n",
    "    num_correct = 0\n",
    "    for test_index in range(num_test_examples):\n",
    "        if test_index % 100 == 1:\n",
    "            print(\"index: %d, current accuracy: %f\" % (test_index, num_correct / test_index)) # TODO: Fill in here.\n",
    "        test_example = test_data.iloc[test_index]\n",
    "        test_label = test_example['v1']\n",
    "        test_input = test_example['v2']\n",
    "        prediction = classify_email(test_input, all_spam_words, all_ham_words, all_words, p_spam, p_ham)\n",
    "        if prediction == test_label:\n",
    "            num_correct += 1\n",
    "    return num_correct / num_test_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Time to test our classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to test the classifier. It'll take awhile to run, but the function periodically prints our test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 1, current accuracy: 1.000000\n",
      "index: 101, current accuracy: 0.891089\n",
      "index: 201, current accuracy: 0.875622\n",
      "index: 301, current accuracy: 0.877076\n",
      "index: 401, current accuracy: 0.882793\n",
      "index: 501, current accuracy: 0.882236\n",
      "index: 601, current accuracy: 0.876872\n",
      "index: 701, current accuracy: 0.873039\n",
      "index: 801, current accuracy: 0.876404\n",
      "index: 901, current accuracy: 0.866815\n",
      "index: 1001, current accuracy: 0.866134\n",
      "index: 1101, current accuracy: 0.867393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681614349775785"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier_accuracy(test_data, all_spam_words, all_ham_words, all_words, p_spam, p_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the final test accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Extra challenge\" sections are a more unguided exploration into the concepts we've discussed. You'll notice less scaffolding for the code -- try implementing these concepts from scratch, and feel free to ask your neighbors or an instructor if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Try calculating the accuracy of our classifier on the train set. How does this compare to the test set?\n",
    "2. Try finding some examples of inaccurately classified examples (or try writing your own input that tricks the classifier). Can you think of any way to improve our classifier?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
